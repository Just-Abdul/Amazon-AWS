{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Natural Language Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBJECTIVE:** Decide if customer complaints should be escalated or not using BlazingText Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the require libraries \n",
    "\n",
    "import pandas as pd                               \n",
    "import boto3\n",
    "import sagemaker\n",
    "import s3fs\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import nltk\n",
    "import csv\n",
    "from time import sleep\n",
    "\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bucket = \"just-abdul-aws\" #Defining bucket name\n",
    "subfolder = \"NLP\"\n",
    "dataset = \"twitter_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "s3 = s3fs.S3FileSystem(anon=False)\n",
    "sm = boto3.Session().client('sagemaker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f's3://{data_bucket}/{subfolder}/{dataset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>in_reply_to</th>\n",
       "      <th>text</th>\n",
       "      <th>escalate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>115713</td>\n",
       "      <td>Tue Oct 31 20:00:43 +0000 2017</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>@sprintcare Since I signed up with you....Sinc...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>115716</td>\n",
       "      <td>Tue Oct 31 22:16:48 +0000 2017</td>\n",
       "      <td>Ask_Spectrum</td>\n",
       "      <td>@Ask_Spectrum Would you like me to email you a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id  author_id                      created_at   in_reply_to  \\\n",
       "0         2     115712  Tue Oct 31 22:11:45 +0000 2017    sprintcare   \n",
       "1         3     115712  Tue Oct 31 22:08:27 +0000 2017    sprintcare   \n",
       "2         5     115712  Tue Oct 31 21:49:35 +0000 2017    sprintcare   \n",
       "3        16     115713  Tue Oct 31 20:00:43 +0000 2017    sprintcare   \n",
       "4        22     115716  Tue Oct 31 22:16:48 +0000 2017  Ask_Spectrum   \n",
       "\n",
       "                                                text  escalate  \n",
       "0      @sprintcare and how do you propose we do that     False  \n",
       "1  @sprintcare I have sent several private messag...      True  \n",
       "2                                 @sprintcare I did.     False  \n",
       "3  @sprintcare Since I signed up with you....Sinc...     False  \n",
       "4  @Ask_Spectrum Would you like me to email you a...     False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520793, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    417800\n",
       "True     102993\n",
       "Name: escalate, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['escalate'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "Y = df['escalate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data set into training and validation set\n",
    "\n",
    "train_df, val_df, _, _ = train_test_split(X, Y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that converts the data to BlazingText Format\n",
    "\n",
    "def preprocess(df):\n",
    "    all_rows = df.values.tolist()\n",
    "    transformed_rows = list(map(transform_instance, all_rows))\n",
    "    transformed_df = pd.DataFrame(transformed_rows)\n",
    "    return transformed_df\n",
    "\n",
    "def transform_instance(row):\n",
    "    cur_row = []\n",
    "    label = \"__label__1\" if row[5] == True else \"__label__0\" # Prefix 0 or 1 from sentiment\n",
    "    cur_row.append(label)\n",
    "    cur_row.extend(nltk.word_tokenize(row[4].lower()))\n",
    "    return ' '.join(cur_row)\n",
    "\n",
    "transformed_validation_rows = preprocess(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__1 @ 115990 no joke ... this is one of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__0 @ amazonhelp primeira camada ... ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__1 @ microsofthelps my mistake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__1 @ 770932 @ americanair they notorio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__1 @ amazonhelp neither man seems to k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  __label__1 @ 115990 no joke ... this is one of...\n",
       "1  __label__0 @ amazonhelp primeira camada ... ht...\n",
       "2             __label__1 @ microsofthelps my mistake\n",
       "3  __label__1 @ 770932 @ americanair they notorio...\n",
       "4  __label__1 @ amazonhelp neither man seems to k..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_validation_rows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the transformed data into amazon s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_validation_data = f's3://{data_bucket}/{subfolder}/processed/validation.csv'\n",
    "\n",
    "data = transformed_validation_rows.to_csv(header=False, index=False, quoting=csv.QUOTE_NONE, sep='|', escapechar='^').encode()\n",
    "\n",
    "with s3.open(s3_validation_data, 'wb') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the training data\n",
    "\n",
    "transformed_training_rows = preprocess(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the training data into amazon S3\n",
    "s3_training_data = f's3://{data_bucket}/{subfolder}/processed/training.csv'\n",
    "\n",
    "training_data = transformed_training_rows.to_csv(header=False, index=False, quoting=csv.QUOTE_NONE, sep='|', escapechar='^').encode()\n",
    "\n",
    "with s3.open(s3_training_data, 'wb') as f:\n",
    "    f.write(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the CSV data for SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.TrainingInput(s3_training_data, distribution='FullyReplicated', \n",
    "                        content_type='text/plain', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.TrainingInput(s3_validation_data, distribution='FullyReplicated', \n",
    "                             content_type='text/plain', s3_data_type='S3Prefix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_max_run has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-27 19:02:00 Starting - Starting the training job...\n",
      "2021-06-27 19:02:23 Starting - Launching requested ML instancesProfilerReport-1624820520: InProgress\n",
      "......\n",
      "2021-06-27 19:03:23 Starting - Preparing the instances for training......\n",
      "2021-06-27 19:04:30 Downloading - Downloading input data...\n",
      "2021-06-27 19:04:44 Training - Downloading the training image..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[06/27/2021 19:05:06 WARNING 139740146722176] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[06/27/2021 19:05:06 WARNING 139740146722176] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[06/27/2021 19:05:06 INFO 139740146722176] nvidia-smi took: 0.02530217170715332 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[06/27/2021 19:05:06 INFO 139740146722176] Running single machine CPU BlazingText training using supervised mode.\u001b[0m\n",
      "\u001b[34mNumber of CPU sockets found in instance is  1\u001b[0m\n",
      "\u001b[34m[06/27/2021 19:05:06 INFO 139740146722176] Processing /opt/ml/input/data/train/training.csv . File size: 32.84108638763428 MB\u001b[0m\n",
      "\u001b[34m[06/27/2021 19:05:06 INFO 139740146722176] Processing /opt/ml/input/data/validation/validation.csv . File size: 21.904098510742188 MB\u001b[0m\n",
      "\u001b[34mRead 6M words\u001b[0m\n",
      "\u001b[34mNumber of words:  20796\u001b[0m\n",
      "\u001b[34mLoading validation data from /opt/ml/input/data/validation/validation.csv\u001b[0m\n",
      "\u001b[34mLoaded validation data.\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 1\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0422  Progress: 15.55%  Million Words/sec: 7.79 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0393  Progress: 21.38%  Million Words/sec: 8.27 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 2\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0365  Progress: 26.98%  Million Words/sec: 8.49 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 3\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0336  Progress: 32.73%  Million Words/sec: 8.68 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0307  Progress: 38.51%  Million Words/sec: 8.83 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 4\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0279  Progress: 44.29%  Million Words/sec: 8.95 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0248  Progress: 50.46%  Million Words/sec: 8.87 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 5\u001b[0m\n",
      "\u001b[34mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.915811\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0218  Progress: 56.43%  Million Words/sec: 8.32 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 6\u001b[0m\n",
      "\u001b[34mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.915015\u001b[0m\n",
      "\u001b[34mValidation accuracy has not improved for last 1 epochs.\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0190  Progress: 62.06%  Million Words/sec: 8.00 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0161  Progress: 67.86%  Million Words/sec: 8.13 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 7\u001b[0m\n",
      "\u001b[34mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.915509\u001b[0m\n",
      "\u001b[34mValidation accuracy has not improved for last 2 epochs.\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0133  Progress: 73.34%  Million Words/sec: 7.88 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0104  Progress: 79.18%  Million Words/sec: 8.00 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 8\u001b[0m\n",
      "\u001b[34mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.916733\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0075  Progress: 84.96%  Million Words/sec: 7.74 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0046  Progress: 90.71%  Million Words/sec: 7.84 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 9\u001b[0m\n",
      "\u001b[34mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.917972\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0017  Progress: 96.63%  Million Words/sec: 7.64 #####\u001b[0m\n",
      "\n",
      "2021-06-27 19:05:24 Uploading - Uploading generated training model\u001b[34m-------------- End of epoch: 10\u001b[0m\n",
      "\u001b[34mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.918538\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0000  Progress: 100.00%  Million Words/sec: 7.45 #####\u001b[0m\n",
      "\u001b[34mTraining finished.\u001b[0m\n",
      "\u001b[34mAverage throughput in Million words/sec: 7.45\u001b[0m\n",
      "\u001b[34mTotal training time in seconds: 9.12\n",
      "\u001b[0m\n",
      "\u001b[34m#train_accuracy: 0.9892\u001b[0m\n",
      "\u001b[34mNumber of train examples: 312475\n",
      "\u001b[0m\n",
      "\u001b[34m#validation_accuracy: 0.9185\u001b[0m\n",
      "\u001b[34mNumber of validation examples: 208318\u001b[0m\n",
      "\n",
      "2021-06-27 19:05:44 Completed - Training job completed\n",
      "Training seconds: 72\n",
      "Billable seconds: 72\n"
     ]
    }
   ],
   "source": [
    "s3_output_location = f's3://{data_bucket}/{subfolder}/output'\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'blazingtext', 'latest')\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "                            container,\n",
    "                            role, \n",
    "                            train_instance_count=1, \n",
    "                            train_instance_type='ml.m4.xlarge',\n",
    "                            train_max_run = 600,\n",
    "                            output_path=s3_output_location,\n",
    "                            sagemaker_session=sess)\n",
    "\n",
    "estimator.set_hyperparameters(\n",
    "                            mode=\"supervised\",\n",
    "                            epochs=10,\n",
    "                            vector_dim=10,\n",
    "                            early_stopping=True,\n",
    "                            patience=4,\n",
    "                            min_epochs=5,\n",
    "                            word_ngrams=2)\n",
    "\n",
    "estimator.fit({'train': train_data, 'validation': validation_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hosting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "text_classifier = estimator.deploy(\n",
    "                        initial_instance_count = 1,\n",
    "                        instance_type = 'ml.m4.xlarge',\n",
    "                        endpoint_name=\"NLP-Text-Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the payload into JSON format for the model\n",
    "\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "\n",
    "text_classifier.serializer = JSONSerializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[__label__0]</td>\n",
       "      <td>[0.9982776641845701]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                  prob\n",
       "0  [__label__0]  [0.9982776641845701]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet1 = \"I don't know why they wouldn't fix it!\"\n",
    "\n",
    "tokenized_tweet = [' '.join(nltk.word_tokenize(tweet1))]\n",
    "payload = {\"instances\" : tokenized_tweet}\n",
    "response = text_classifier.predict(payload)\n",
    "escalate = pd.read_json(response)\n",
    "escalate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function for result\n",
    "\n",
    "def Result():\n",
    "    for item in escalate['label']:\n",
    "        i = str(item).replace('[','').replace(']','') # Removes the square brackets\n",
    "        if i == \"'__label__0'\":\n",
    "            print ('Do not Escalate!')\n",
    "        else:\n",
    "            print (\"Escalate!\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do not Escalate!\n"
     ]
    }
   ],
   "source": [
    "tweet2 = \"Excellent service!\"\n",
    "\n",
    "tokenized_tweet = [' '.join(nltk.word_tokenize(tweet2))]\n",
    "payload = {\"instances\" : tokenized_tweet}\n",
    "response = text_classifier.predict(payload)\n",
    "escalate = pd.read_json(response)\n",
    "Result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escalate!\n"
     ]
    }
   ],
   "source": [
    "tweet3 = \"I'm not angry!\"\n",
    "\n",
    "tokenized_tweet = [' '.join(nltk.word_tokenize(tweet3))]\n",
    "payload = {\"instances\" : tokenized_tweet}\n",
    "response = text_classifier.predict(payload)\n",
    "escalate = pd.read_json(response)\n",
    "Result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escalate!\n"
     ]
    }
   ],
   "source": [
    "tweet4 = \"nonsence, slow, annoying, lack, worst!\"\n",
    "\n",
    "tokenized_tweet = [' '.join(nltk.word_tokenize(tweet4))]\n",
    "payload = {\"instances\" : tokenized_tweet}\n",
    "response = text_classifier.predict(payload)\n",
    "escalate = pd.read_json(response)\n",
    "Result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(text_classifier.endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
